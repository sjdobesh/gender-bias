{".class": "MypyFile", "_fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects", "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "DummyObject": {".class": "SymbolTableNode", "cross_ref": "transformers.file_utils.DummyObject", "kind": "Gdef"}, "SLOW_TO_FAST_CONVERTERS": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.SLOW_TO_FAST_CONVERTERS", "name": "SLOW_TO_FAST_CONVERTERS", "type": {".class": "NoneType"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.__package__", "name": "__package__", "type": "builtins.str"}}, "convert_slow_tokenizer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "arg_kinds": [2, 4], "arg_names": ["args", "kwargs"], "flags": [], "fullname": "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.convert_slow_tokenizer", "name": "convert_slow_tokenizer", "type": null}}, "requires_backends": {".class": "SymbolTableNode", "cross_ref": "transformers.file_utils.requires_backends", "kind": "Gdef"}}, "path": "/home/s/.local/lib/python3.8/site-packages/transformers/utils/dummy_sentencepiece_and_tokenizers_objects.py"}