{"data_mtime": 1644265232, "dep_lines": [18, 19, 20, 21, 25, 26, 26, 30, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 23], "dep_prios": [10, 10, 5, 5, 5, 20, 10, 25, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30, 10], "dependencies": ["json", "os", "functools", "typing", "transformers.tokenization_utils", "transformers.utils", "transformers.utils.logging", "transformers.pipelines.conversational", "builtins", "torch.nn.functional", "pickle", "re", "torch.nn.quantized", "torch.nn.intrinsic.qat", "torch.nn.intrinsic.quantized", "inspect", "itertools", "operator", "warnings", "torch.nn.qat", "copy", "torch", "torch.nn.intrinsic", "enum", "collections", "torch.nn", "torch.nn.quantized.dynamic", "contextlib", "logging", "threading", "_typeshed", "abc", "io", "json.decoder", "json.encoder", "transformers.file_utils", "transformers.pipelines", "transformers.tokenization_utils_base", "typing_extensions"], "hash": "8a1323b7d5693da79f182d7a0aec788f34aec740195331351b10e02cc21403db", "id": "transformers.models.gpt2.tokenization_gpt2", "ignore_all": true, "interface_hash": "6bc66e0cf36570c9079c13ed5f0024aa495dd0a46f5725e58229c394852855df", "mtime": 1643924561, "options": {"allow_redefinition": false, "allow_untyped_globals": false, "always_false": [], "always_true": [], "bazel": false, "check_untyped_defs": false, "disallow_any_decorated": false, "disallow_any_explicit": false, "disallow_any_expr": false, "disallow_any_generics": false, "disallow_any_unimported": false, "disallow_incomplete_defs": false, "disallow_subclassing_any": false, "disallow_untyped_calls": false, "disallow_untyped_decorators": false, "disallow_untyped_defs": false, "follow_imports": "normal", "follow_imports_for_stubs": false, "ignore_errors": false, "ignore_missing_imports": false, "implicit_reexport": true, "local_partial_types": false, "mypyc": false, "no_implicit_optional": false, "platform": "linux", "plugins": [], "show_none_errors": true, "strict_equality": false, "strict_optional": true, "strict_optional_whitelist": null, "warn_no_return": true, "warn_return_any": false, "warn_unreachable": false, "warn_unused_ignores": false}, "path": "/home/s/.local/lib/python3.8/site-packages/transformers/models/gpt2/tokenization_gpt2.py", "plugin_data": null, "size": 12258, "suppressed": ["regex"], "version_id": "0.902"}