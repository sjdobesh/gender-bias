{".class": "MypyFile", "_fullname": "transformers.models.longformer.tokenization_longformer", "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "LongformerTokenizer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": null, "abstract_attributes": [], "bases": ["transformers.models.roberta.tokenization_roberta.RobertaTokenizer"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.longformer.tokenization_longformer.LongformerTokenizer", "name": "LongformerTokenizer", "type_vars": []}, "flags": [], "fullname": "transformers.models.longformer.tokenization_longformer.LongformerTokenizer", "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.longformer.tokenization_longformer", "mro": ["transformers.models.longformer.tokenization_longformer.LongformerTokenizer", "transformers.models.roberta.tokenization_roberta.RobertaTokenizer", "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer", "transformers.tokenization_utils.PreTrainedTokenizer", "transformers.tokenization_utils_base.PreTrainedTokenizerBase", "transformers.tokenization_utils_base.SpecialTokensMixin", "transformers.file_utils.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "max_model_input_sizes": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.max_model_input_sizes", "name": "max_model_input_sizes", "type": null}}, "pretrained_vocab_files_map": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.pretrained_vocab_files_map", "name": "pretrained_vocab_files_map", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "vocab_files_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.vocab_files_names", "name": "vocab_files_names", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}}, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.longformer.tokenization_longformer.PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "name": "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.int"], "type_ref": "builtins.dict"}}}, "PRETRAINED_VOCAB_FILES_MAP": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.longformer.tokenization_longformer.PRETRAINED_VOCAB_FILES_MAP", "name": "PRETRAINED_VOCAB_FILES_MAP", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "RobertaTokenizer": {".class": "SymbolTableNode", "cross_ref": "transformers.models.roberta.tokenization_roberta.RobertaTokenizer", "kind": "Gdef"}, "VOCAB_FILES_NAMES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.longformer.tokenization_longformer.VOCAB_FILES_NAMES", "name": "VOCAB_FILES_NAMES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.longformer.tokenization_longformer.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.longformer.tokenization_longformer.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.longformer.tokenization_longformer.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.longformer.tokenization_longformer.__package__", "name": "__package__", "type": "builtins.str"}}, "logger": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.longformer.tokenization_longformer.logger", "name": "logger", "type": "logging.Logger"}}, "logging": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.logging", "kind": "Gdef"}}, "path": "/home/s/.local/lib/python3.8/site-packages/transformers/models/longformer/tokenization_longformer.py"}