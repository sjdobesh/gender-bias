{"data_mtime": 1644265232, "dep_lines": [16, 16, 17, 18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "dep_prios": [20, 10, 5, 5, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30], "dependencies": ["transformers.utils", "transformers.utils.logging", "transformers.models.roberta.tokenization_roberta_fast", "transformers.models.longformer.tokenization_longformer", "builtins", "torch.nn.functional", "pickle", "re", "torch.nn.quantized", "torch.nn.intrinsic.qat", "torch.nn.intrinsic.quantized", "inspect", "itertools", "operator", "warnings", "torch.nn.qat", "copy", "functools", "torch", "torch.nn.intrinsic", "enum", "collections", "torch.nn", "torch.nn.quantized.dynamic", "contextlib", "logging", "threading", "abc", "transformers.file_utils", "transformers.models.gpt2", "transformers.models.gpt2.tokenization_gpt2", "transformers.models.roberta", "transformers.models.roberta.tokenization_roberta", "transformers.tokenization_utils", "transformers.tokenization_utils_base", "typing"], "hash": "c787a5c071f0155f206386617749e53300209cd82b5cef46a3beb92788b41ea5", "id": "transformers.models.longformer.tokenization_longformer_fast", "ignore_all": true, "interface_hash": "305d75dc4e15d0a2a5e2c68fe0186189ab63765dd4daac08e9aa2b2c210af9c2", "mtime": 1643924561, "options": {"allow_redefinition": false, "allow_untyped_globals": false, "always_false": [], "always_true": [], "bazel": false, "check_untyped_defs": false, "disallow_any_decorated": false, "disallow_any_explicit": false, "disallow_any_expr": false, "disallow_any_generics": false, "disallow_any_unimported": false, "disallow_incomplete_defs": false, "disallow_subclassing_any": false, "disallow_untyped_calls": false, "disallow_untyped_decorators": false, "disallow_untyped_defs": false, "follow_imports": "normal", "follow_imports_for_stubs": false, "ignore_errors": false, "ignore_missing_imports": false, "implicit_reexport": true, "local_partial_types": false, "mypyc": false, "no_implicit_optional": false, "platform": "linux", "plugins": [], "show_none_errors": true, "strict_equality": false, "strict_optional": true, "strict_optional_whitelist": null, "warn_no_return": true, "warn_return_any": false, "warn_unreachable": false, "warn_unused_ignores": false}, "path": "/home/s/.local/lib/python3.8/site-packages/transformers/models/longformer/tokenization_longformer_fast.py", "plugin_data": null, "size": 4150, "suppressed": [], "version_id": "0.902"}