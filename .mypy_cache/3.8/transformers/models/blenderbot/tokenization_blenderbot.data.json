{".class": "MypyFile", "_fullname": "transformers.models.blenderbot.tokenization_blenderbot", "is_partial_stub_package": false, "is_stub": false, "names": {".class": "SymbolTable", "BlenderbotTokenizer": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "TypeInfo", "_promote": null, "abstract_attributes": [], "bases": ["transformers.models.roberta.tokenization_roberta.RobertaTokenizer"], "declared_metaclass": null, "defn": {".class": "ClassDef", "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer", "name": "BlenderbotTokenizer", "type_vars": []}, "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer", "metaclass_type": null, "metadata": {}, "module_name": "transformers.models.blenderbot.tokenization_blenderbot", "mro": ["transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer", "transformers.models.roberta.tokenization_roberta.RobertaTokenizer", "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer", "transformers.tokenization_utils.PreTrainedTokenizer", "transformers.tokenization_utils_base.PreTrainedTokenizerBase", "transformers.tokenization_utils_base.SpecialTokensMixin", "transformers.file_utils.PushToHubMixin", "builtins.object"], "names": {".class": "SymbolTable", "_build_conversation_input_ids": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "arg_kinds": [0, 0], "arg_names": ["self", "conversation"], "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer._build_conversation_input_ids", "name": "_build_conversation_input_ids", "type": {".class": "CallableType", "arg_kinds": [0, 0], "arg_names": ["self", "conversation"], "arg_types": ["transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer", "transformers.pipelines.conversational.Conversation"], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "implicit": false, "is_ellipsis_args": false, "name": "_build_conversation_input_ids of BlenderbotTokenizer", "ret_type": {".class": "Instance", "args": ["builtins.int"], "type_ref": "builtins.list"}, "type_guard": null, "variables": []}}}, "build_inputs_with_special_tokens": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "FuncDef", "arg_kinds": [0, 0, 1], "arg_names": ["self", "token_ids_0", "token_ids_1"], "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.build_inputs_with_special_tokens", "name": "build_inputs_with_special_tokens", "type": {".class": "CallableType", "arg_kinds": [0, 0, 1], "arg_names": ["self", "token_ids_0", "token_ids_1"], "arg_types": ["transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer", {".class": "Instance", "args": ["builtins.int"], "type_ref": "builtins.list"}, {".class": "UnionType", "items": [{".class": "Instance", "args": ["builtins.int"], "type_ref": "builtins.list"}, {".class": "NoneType"}]}], "bound_args": [], "def_extras": {"first_arg": "self"}, "fallback": "builtins.function", "implicit": false, "is_ellipsis_args": false, "name": "build_inputs_with_special_tokens of BlenderbotTokenizer", "ret_type": {".class": "AnyType", "missing_import_name": null, "source_any": null, "type_of_any": 1}, "type_guard": null, "variables": []}}}, "max_model_input_sizes": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.max_model_input_sizes", "name": "max_model_input_sizes", "type": null}}, "pretrained_vocab_files_map": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.pretrained_vocab_files_map", "name": "pretrained_vocab_files_map", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "vocab_files_names": {".class": "SymbolTableNode", "kind": "Mdef", "node": {".class": "Var", "flags": ["is_initialized_in_class"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.vocab_files_names", "name": "vocab_files_names", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}}, "tuple_type": null, "type_vars": [], "typeddict_type": null}}, "Conversation": {".class": "SymbolTableNode", "cross_ref": "transformers.pipelines.conversational.Conversation", "kind": "Gdef"}, "List": {".class": "SymbolTableNode", "cross_ref": "typing.List", "kind": "Gdef"}, "Optional": {".class": "SymbolTableNode", "cross_ref": "typing.Optional", "kind": "Gdef"}, "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "name": "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.int"], "type_ref": "builtins.dict"}}}, "PRETRAINED_VOCAB_FILES_MAP": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.PRETRAINED_VOCAB_FILES_MAP", "name": "PRETRAINED_VOCAB_FILES_MAP", "type": {".class": "Instance", "args": ["builtins.str", {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}], "type_ref": "builtins.dict"}}}, "RobertaTokenizer": {".class": "SymbolTableNode", "cross_ref": "transformers.models.roberta.tokenization_roberta.RobertaTokenizer", "kind": "Gdef"}, "TYPE_CHECKING": {".class": "SymbolTableNode", "cross_ref": "typing.TYPE_CHECKING", "kind": "Gdef"}, "VOCAB_FILES_NAMES": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.VOCAB_FILES_NAMES", "name": "VOCAB_FILES_NAMES", "type": {".class": "Instance", "args": ["builtins.str", "builtins.str"], "type_ref": "builtins.dict"}}}, "__doc__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.__doc__", "name": "__doc__", "type": "builtins.str"}}, "__file__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.__file__", "name": "__file__", "type": "builtins.str"}}, "__name__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.__name__", "name": "__name__", "type": "builtins.str"}}, "__package__": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": ["is_ready"], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.__package__", "name": "__package__", "type": "builtins.str"}}, "get_pairs": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "FuncDef", "arg_kinds": [0], "arg_names": ["word"], "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.get_pairs", "name": "get_pairs", "type": null}}, "logger": {".class": "SymbolTableNode", "kind": "Gdef", "node": {".class": "Var", "flags": [], "fullname": "transformers.models.blenderbot.tokenization_blenderbot.logger", "name": "logger", "type": "logging.Logger"}}, "logging": {".class": "SymbolTableNode", "cross_ref": "transformers.utils.logging", "kind": "Gdef"}}, "path": "/home/s/.local/lib/python3.8/site-packages/transformers/models/blenderbot/tokenization_blenderbot.py"}